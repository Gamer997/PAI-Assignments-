{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a620c0",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "After successfully completing your degree, hopefully within eight semesters xD, you're embarking on the job search phase. Traditional job hunting can be a bit boring, so why not consider automation as a solution? Luckily, your PAI class introduced you to Selenium, an automation tool.\n",
    "\n",
    "You've thinking of developing a simple script to navigate rozee.pk and indeed websites, searching for AI/ML Engineer positions. This script extracts crucial information from each job listing, such as job titles, company names, job locations, gender preferences, age requirements, minimum education levels, and experience details (if available). All this data should be neatly organized into a Pandas dataframe, including links to the job listings. Perform analysis on dataframe to find a job which best suits you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI / ML Application Developer\n",
      "HRK Software Park,Lahore, Pakistan\n",
      "Apply for job\n",
      "Share this job\n",
      "Job Description\n",
      "We are searching for a talented AI and Machine Learning Application Developer to join our team. This role involves designing, developing, and implementing innovative AI and ML solutions.\n",
      "The ideal candidate will have a deep understanding of AI concepts, proficiency in programming languages such as Python, and hands-on experience with various AI and ML frameworks.\n",
      "If you are passionate about pushing the boundaries of technology and creating impactful applications, this is the opportunity for you.\n",
      "Job Skills\n",
      "Python\n",
      "C\n",
      "#ML\n",
      "Digital Image Processing\n",
      "Job Details\n",
      "Industry:\n",
      "Information Technology\n",
      "Functional Area:\n",
      "Software & Web Development\n",
      "Total Positions:\n",
      "1 Post\n",
      "Job Shift:\n",
      "First Shift (Day)\n",
      "Job Type:\n",
      "Full Time/Permanent\n",
      "Job Location:\n",
      "Lahore, Pakistan\n",
      "Gender\n",
      "No Preference\n",
      "Minimum Education\n",
      "Bachelor\n",
      "Career Level\n",
      "Entry Level\n",
      "Minimum Experience\n",
      "2 Years\n",
      "Apply Before:\n",
      "Dec 21, 2023\n",
      "Posting Date:\n",
      "Nov 21, 2023\n",
      "hello\n",
      "Software Engineer (AI/ML/NLP)\n",
      "Riphah International University,Islamabad, Pakistan\n",
      "Apply for job\n",
      "Share this job\n",
      "Job Description\n",
      "Are you a seasoned Software Engineer If yes, then an exciting career opportunity awaits YOU!\n",
      "Job Education: BS/MS in Computer Sciences, Software engineering, Data Science\n",
      "Job Experience: 2 to 3 Years\n",
      "Job Description:\n",
      "Utilize open-source software to craft advanced chatbots, pushing the boundaries of conversational AI.\n",
      "Apply machine learning models to existing datasets, leveraging predictive analytics to enhance decision-making processes.\n",
      "Collaborate with fellow engineers to develop a comprehensive understanding of AI development, fostering an environment of knowledge-sharing.\n",
      "Document each step of the process to ensure a transparent and auditable AI development process, with a focus on maintaining human oversight.\n",
      "Demonstrate a solid understanding of best practices in AI and ML, encompassing model building, automation, neural network enrichment, iterative learning, and adept problem-solving.\n",
      "Understand of prompt engineering on OpenAI and open source LLM models.\n",
      "Train, fine-tune, and evaluate machine learning models using different techniques. Implement and experiment with various model architectures to improve performance.\n",
      "Work with large datasets to extract meaningful insights. Develop data preprocessing pipelines and conduct exploratory data analysis to identify patterns and trends.\n",
      "Python, OpenAI, Natural Language Processing (NLP), Large Language Models (LLMs)\n",
      " Job Skills\n",
      "LLM\n",
      "AI\n",
      "ML\n",
      "NLP\n",
      "Software Engineering\n",
      "Job Details\n",
      "Industry:\n",
      "Education/Training\n",
      "Functional Area:\n",
      "Software & Web Development\n",
      "Total Positions:\n",
      "1 Post\n",
      "Job Shift:\n",
      "First Shift (Day)\n",
      "Job Type:\n",
      "Full Time/Permanent\n",
      "Department:\n",
      "CSD\n",
      "Job Location:\n",
      "Islamabad, Pakistan\n",
      "Gender\n",
      "No Preference\n",
      "Minimum Education\n",
      "Bachelor\n",
      "Degree Title\n",
      "BS/MS in Computer Sciences, Software engineering, Data Science\n",
      "Career Level\n",
      "Experienced Professional\n",
      "Experience\n",
      "2 Years - 3 Years\n",
      "Apply Before:\n",
      "Dec 01, 2023\n",
      "Posting Date:\n",
      "Nov 20, 2023\n",
      "hello\n",
      "Manager AI\n",
      "MTBC,Multiple Cities, Pakistan\n",
      "Apply for job\n",
      "Share this job\n",
      "Job Description\n",
      "As a Manager AI (Artificial Intelligence), your primary responsibility is to oversee and lead the development and implementation of AI initiatives within an organization. You will be responsible for driving the AI strategy, managing AI projects, and ensuring that AI technologies and solutions align with the company's goals and objectives. Your role will involve collaborating with cross-functional teams, including data scientists, engineers, and business stakeholders, to deliver effective AI solutions.\n",
      "Responsibilities:\n",
      "Develop and execute the AI strategy: Define the organization's AI roadmap, goals, and priorities. Identify potential AI applications and opportunities for improving business processes and customer experiences.\n",
      "Lead AI projects: Manage end-to-end AI projects, including scoping, planning, resource allocation, and execution. Monitor project progress, identify risks and issues, and implement corrective actions to ensure successful project delivery.\n",
      "Collaborate with stakeholders: Work closely with business leaders, product managers, and subject matter experts to understand their requirements and translate them into AI solutions. Provide guidance on the feasibility and impact of AI initiatives.\n",
      "Manage AI teams: Recruit, mentor, and manage a team of AI professionals, including data scientists, machine learning engineers, and AI developers. Foster a collaborative and innovative work environment, and promote continuous learning and development.\n",
      "Stay updated with AI trends and technologies: Monitor the latest advancements in AI and related fields. Evaluate emerging AI technologies, tools, and frameworks, and assess their potential impact on the organization. Make recommendations for adopting new AI solutions.\n",
      "Ensure data quality and governance: Collaborate with data management teams to establish data quality standards, data governance frameworks, and data privacy protocols. Ensure compliance with applicable regulations, such as GDPR or CCPA.\n",
      "Evaluate AI performance: Establish metrics and performance indicators to assess the effectiveness and efficiency of AI models and solutions. Monitor and analyze AI performance data to identify areas for improvement and optimize AI algorithms.\n",
      "Job Skills\n",
      "Problem Solving\n",
      "Analytical Thinking\n",
      "Leadership Skills\n",
      "Pytoch\n",
      "Tensorflow\n",
      "Python\n",
      "Job Details\n",
      "Industry:\n",
      "Information Technology\n",
      "Functional Area:\n",
      "Software & Web Development\n",
      "Total Positions:\n",
      "1 Post\n",
      "Job Shift:\n",
      "Second Shift (Afternoon)\n",
      "Job Type:\n",
      "Full Time/Permanent\n",
      "Department:\n",
      "IT\n",
      "Job Location:\n",
      "Islamabad, Karachi, Rawalpindi, Pakistan\n",
      "Gender\n",
      "No Preference\n",
      "Minimum Education\n",
      "Bachelor\n",
      "Degree Title\n",
      "Information Technology / Computer Science\n",
      "Career Level\n",
      "Experienced Professional\n",
      "Minimum Experience\n",
      "7 Years\n",
      "Apply Before:\n",
      "Dec 22, 2023\n",
      "Posting Date:\n",
      "Nov 21, 2023\n",
      "hello\n",
      "AI Engineer\n",
      "Legalator AI,Islamabad, Pakistan\n",
      "Apply for job\n",
      "Share this job\n",
      "Job Description\n",
      "As an AI Model Operations Engineer, you will play a pivotal role in maintaining, optimizing, and fine-tuning our AI model ecosystem. You will work in collaboration with our development and research teams to ensure that our AI-Powered Legal Search Engine delivers accurate, high-quality results while minimizing any potential for inaccuracies. Your responsibilities will encompass a broad spectrum of tasks, from data preprocessing to model query management, all aimed at enhancing user experience and maximizing the utility of our platform.\n",
      "Key Responsibilities:\n",
      "Data Preprocessing\n",
      "Model Query Management\n",
      "Model Integration\n",
      "Performance Optimization\n",
      "Statistical Recording\n",
      "Infrastructure Management\n",
      "Qualifications:\n",
      "Bachelor's or Master's degree in Computer Science, Artificial Intelligence, or a related field.\n",
      "Proven experience in AI model operations, particularly with GPT models and embeddings.\n",
      "Strong proficiency in Python, HTML, CSS, and JavaScript.\n",
      "Familiarity with Flask, Pinecone, Google Datastore, and Google App Engine.\n",
      "Exceptional problem-solving skills and attention to detail.\n",
      "Strong communication and teamwork skills.\n",
      "Job Skills\n",
      "Flask\n",
      "Google App Engine\n",
      "Cloud Systems\n",
      "JavaScript\n",
      "CSS\n",
      "HTML\n",
      "Python Framework Command\n",
      "Artificial Intelligence Knowledge\n",
      "Job Details\n",
      "Industry:\n",
      "Law Firms/Legal\n",
      "Functional Area:\n",
      "Software & Web Development\n",
      "Total Positions:\n",
      "1 Post\n",
      "Job Shift:\n",
      "First Shift (Day)\n",
      "Job Type:\n",
      "Full Time/Permanent\n",
      "Job Location:\n",
      "Islamabad, Pakistan\n",
      "Gender\n",
      "No Preference\n",
      "Minimum Education\n",
      "Bachelor\n",
      "Career Level\n",
      "Entry Level\n",
      "Minimum Experience\n",
      "1 Year\n",
      "Apply Before:\n",
      "Nov 27, 2023\n",
      "Posting Date:\n",
      "Oct 26, 2023\n",
      "hello\n",
      "Design Sales Consultant\n",
      "AI Technologies,Karachi, Pakistan\n",
      "Apply for job\n",
      "Share this job\n",
      "Job Description\n",
      "This is a full-time on-site role for a Sales Design Consultant with AI Technologies in Karachi. As a Sales Design Consultant, you will work closely with customers to design and sell customized technology solutions that meet their business needs. You will be responsible for identifying sales opportunities, managing client relationships, and collaborating with cross-functional teams to design and deliver high-quality solutions.\n",
      "Qualifications:\n",
      "Excellent communication, negotiation and customer service skills\n",
      "Experience in sales, business analysis, design or architecture\n",
      "Demonstrable experience facilitating workshops and leading customer discovery sessions\n",
      "Experience with design thinking, agile delivery practices and project management\n",
      "A track record of achieving sales and revenue targets\n",
      "Ability to collaborate effectively with teams across enterprise and customer organizations\n",
      "Experience with cloud technologies, digital transformation, AI, ML and data analytics is a strong plus\n",
      "Bachelor's degree or higher in Computer Science, Engineering or a related field\n",
      "Job Skills\n",
      "Client Dealing\n",
      "Communication Skills\n",
      "Telesales\n",
      "Job Details\n",
      "Industry:\n",
      "Consultants\n",
      "Functional Area:\n",
      "Sales & Business Development\n",
      "Job Shift:\n",
      "First Shift (Day)\n",
      "Job Type:\n",
      "Full Time/Permanent\n",
      "Job Location:\n",
      "Gulshan-e-Iqbal, Karachi, Pakistan\n",
      "Gender\n",
      "No Preference\n",
      "Minimum Education\n",
      "Intermediate/A-Level\n",
      "Degree Title\n",
      "Computer Science, Engineering or a related field\n",
      "Career Level\n",
      "Entry Level\n",
      "Minimum Experience\n",
      "1 Year\n",
      "Apply Before:\n",
      "Dec 03, 2023\n",
      "Posting Date:\n",
      "Nov 02, 2023\n",
      "hello\n",
      "Business Development Officer\n",
      "Ai Professionals (Pvt) Limited,Islamabad, Pakistan\n",
      "PKR. 40,000 - 50,000 /Month\n",
      "Apply for job\n",
      "Share this job\n",
      "Job Description\n",
      "We are looking for an ambitious and energetic Business Development Officer to help us expand our clinical partnership. \n",
      "The goal is to drive sustainable financial growth by boosting sales and forging strong relationships with clinics and physicians.\n",
      "  Job Skills\n",
      "Business Development\n",
      "Sales\n",
      "Relationship Building\n",
      "Job Details\n",
      "Industry:\n",
      "Consultants\n",
      "Functional Area:\n",
      "Sales & Business Development\n",
      "Total Positions:\n",
      "3 Posts\n",
      "Job Shift:\n",
      "First Shift (Day)\n",
      "Job Type:\n",
      "Full Time/Permanent\n",
      "Job Location:\n",
      "Islamabad, Pakistan\n",
      "Gender\n",
      "No Preference\n",
      "Minimum Education\n",
      "Bachelor\n",
      "Career Level\n",
      "Entry Level\n",
      "Minimum Experience\n",
      "Less than 1 Year\n",
      "Apply Before:\n",
      "Dec 14, 2023\n",
      "Posting Date:\n",
      "Nov 13, 2023\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "def scrape_rozee_and_indeed():\n",
    "    # Set up Chrome options\n",
    "    # chrome_options = webdriver.ChromeOptions()\n",
    "    # chrome_options.add_argument('/path/to/chromedriver')  # Specify the path to chromedriver\n",
    "\n",
    "    # # Create a Chrome webdriver with the specified options\n",
    "    # driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    # Open rozee.pk\n",
    "    driver.get('https://www.indeed.com/')\n",
    "\n",
    "    # Use WebDriverWait to wait for the search bar to be visible\n",
    "    search_bar = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '/html/body/div[2]/div[3]/div[2]/form/div[1]/input'))\n",
    "    )\n",
    "\n",
    "    # Input the search query\n",
    "    search_bar.send_keys('AI/ML Engineer')\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Extract job information\n",
    "    # Extract job information\n",
    "    jobs_details = driver.find_element(By.XPATH, '//*[@id=\"jobs\"]')\n",
    "    job_cards = jobs_details.find_elements(By.CLASS_NAME, 'job ')\n",
    "    for i in range(len(job_cards)):\n",
    "        # Find the job cards again to avoid StaleElementReferenceException\n",
    "\n",
    "\n",
    "        # Click on the current job card\n",
    "        current_job_card = job_cards[i]\n",
    "        \n",
    "        current_job_card.click()\n",
    "\n",
    "        # Wait for the page to load\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            jobDetailss = driver.find_element(By.XPATH, '//*[@id=\"jobDetail\"]')\n",
    "            detail = jobDetailss.find_elements(By.XPATH,'//*[@id=\"job-header\"]')\n",
    "            print(jobDetailss.text)\n",
    "            print(detail.text)\n",
    "        except:\n",
    "            print(\"hello\")\n",
    "        # Do whatever you need to do on the job details page\n",
    "\n",
    "        # Go back to the previous page\n",
    "        \n",
    "\n",
    "        # Wait for the jobs details page to be present again to avoid StaleElementReferenceException\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"jobs\"]')))\n",
    "\n",
    "scrape_rozee_and_indeed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job details:\n",
      "Company Name: \n",
      "Location: No Preference\n",
      "Job Title: AI / ML Application Developer\n",
      "Minimum Education: Bachelor\n",
      "Gender Preference: No Preference\n",
      "Experience Required: 2 Years\n",
      "\n",
      "Job details:\n",
      "Company Name: \n",
      "Location: Islamabad, Pakistan\n",
      "Job Title: Software Engineer (AI/ML/NLP)\n",
      "Minimum Education: No Preference\n",
      "Gender Preference: Islamabad, Pakistan\n",
      "Experience Required: BS/MS in Computer Sciences, Software engineering, Data Science\n",
      "exception\n",
      "\n",
      "Job details:\n",
      "Company Name: \n",
      "Location: No Preference\n",
      "Job Title: AI Engineer\n",
      "Minimum Education: Bachelor\n",
      "Gender Preference: No Preference\n",
      "Experience Required: 1 Year\n",
      "\n",
      "Job details:\n",
      "Company Name: \n",
      "Location: Intermediate/A-Level\n",
      "Job Title: Design Sales Consultant\n",
      "Minimum Education: Computer Science, Engineering or a related field\n",
      "Gender Preference: Intermediate/A-Level\n",
      "Experience Required: 1 Year\n",
      "exception\n",
      "exception\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "def scrape_rozee():\n",
    "\n",
    "    # Open rozee.pk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    driver.get('https://www.rozee.pk/')\n",
    "\n",
    "    # Use WebDriverWait to wait for the search bar to be visible\n",
    "    search_bar = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '/html/body/div[2]/div[3]/div[2]/form/div[1]/input'))\n",
    "    )\n",
    "\n",
    "    # Input the search query\n",
    "    search_bar.send_keys('AI/ML Engineer')\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Extract job information\n",
    "    \n",
    "    jobs_details = driver.find_element(By.XPATH, '//*[@id=\"jobs\"]')\n",
    "    job_cards = jobs_details.find_elements(By.CLASS_NAME, 'job ')\n",
    "    \n",
    "    for i in range(len(job_cards)):\n",
    "        # Find the job cards again to avoid StaleElementReferenceException\n",
    "\n",
    "\n",
    "        # Click on the current job card\n",
    "        current_job_card = job_cards[i]\n",
    "        \n",
    "        current_job_card.click()\n",
    "\n",
    "        # Wait for the page to load\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            time.sleep(5)\n",
    "            jobDetailss = driver.find_element(By.XPATH, '//*[@id=\"jobDetail\"]')\n",
    "            \n",
    "            job_details = driver.find_element(By.XPATH, '//*[@id=\"jobDetail\"]')\n",
    "\n",
    "            job_title = job_details.find_element(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[1]/div[1]/div[1]/div[3]/h1')\n",
    "            min_education = job_details.find_element(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[2]/div[3]/div/div[8]/div[2]').text if job_details.find_elements(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[2]/div[3]/div/div[8]/div[2]') else \"Not specified\"\n",
    "            gender_preference = job_details.find_element(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[2]/div[3]/div/div[7]/div[2]').text if job_details.find_elements(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[2]/div[3]/div/div[7]/div[2]') else \"Not specified\"\n",
    "            experience_details = job_details.find_element(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[2]/div[3]/div/div[10]/div[2]').text if job_details.find_elements(By.XPATH, '/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[2]/div[3]/div/div[10]/div[2]') else \"Not specified\"\n",
    "            company_name = job_details.find_element(By.CLASS_NAME, 'clearfix')\n",
    "            job_location = job_details.find_element(By.XPATH, '//*[@id=\"job-content\"]/div[3]/div/div[7]/div[2]')\n",
    "            print(f\"\\nJob details:\")\n",
    "            print(f\"Company Name: {company_name.text}\")\n",
    "            print(f\"Location: {job_location.text}\")\n",
    "            print(f\"Job Title: {job_title.text}\")\n",
    "            print(f\"Minimum Education: {min_education}\")\n",
    "            print(f\"Gender Preference: {gender_preference}\")\n",
    "            print(f\"Experience Required: {experience_details}\")\n",
    "\n",
    "        except:\n",
    "            print(\"exception\")\n",
    "        # Do whatever you need to do on the job details page\n",
    "\n",
    "        # Go back to the previous page\n",
    "        driver.back()\n",
    "\n",
    "        # Wait for the jobs details page to be present again to avoid StaleElementReferenceException\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"jobs\"]')))\n",
    "scrape_rozee()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job details:\n",
      "Company Name: BCDAPPS (PVT) LIMITED\n",
      "Location: Islamabad\n",
      "Job Title: ML/NLP Engineer\n",
      "- job post\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def scrape_indeed():\n",
    "    # Initialize WebDriver\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "    # Open Indeed\n",
    "    driver.get('https://www.indeed.com/')\n",
    "\n",
    "    # Use WebDriverWait to wait for the search bar to be visible\n",
    "    search_bar = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '//*[@id=\"text-input-what\"]'))\n",
    "    )\n",
    "\n",
    "    # Input the search query\n",
    "    search_bar.send_keys('AI/ML Engineer')\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Extract job information\n",
    "    jobs_details = driver.find_element(By.ID, 'jobsearch-JapanPage')\n",
    "    job_cards = driver.find_elements(By.XPATH, '//*[@id=\"mosaic-provider-jobcards\"]/ul/li[1]/div/div[1]/div/div[1]')\n",
    "\n",
    "    for i in range(min(4, len(job_cards))):  # Ensure we don't go beyond the number of available job cards\n",
    "        # Find the job cards again to avoid StaleElementReferenceException\n",
    "        jobs_details = driver.find_element(By.ID, 'jobsearch-JapanPage')\n",
    "        job_cards = driver.find_elements(By.XPATH, '//*[@id=\"mosaic-provider-jobcards\"]/ul/li[1]/div/div[1]/div/div[1]')\n",
    "\n",
    "        # Click on the current job card\n",
    "        current_job_card = job_cards[i]\n",
    "        current_job_card.click()\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            job_details = driver.find_element(By.ID, 'jobsearch-ViewjobPaneWrapper')\n",
    "\n",
    "            job_title = job_details.find_element(By.XPATH, '/html/body/main/div/div[1]/div/div[5]/div[2]/div/div/div/div/div[1]/div/div[1]/div[1]/h2')\n",
    "            company_name = job_details.find_element(By.XPATH, '/html/body/main/div/div[1]/div/div[5]/div[2]/div/div/div/div/div[1]/div/div[1]/div[2]/div/div/div/div[1]/div/span')\n",
    "            job_location = job_details.find_element(By.XPATH, '//*[@id=\"jobsearch-ViewjobPaneWrapper\"]/div/div/div/div[1]/div/div[1]/div[2]/div/div/div/div[2]')\n",
    "\n",
    "            print(f\"\\nJob details:\")\n",
    "            print(f\"Company Name: {company_name.text}\")\n",
    "            print(f\"Location: {job_location.text}\")\n",
    "            print(f\"Job Title: {job_title.text}\")\n",
    "\n",
    "        except:\n",
    "            print(\"Exception while extracting job details\")\n",
    "\n",
    "        # Go back to the previous page\n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "        # Wait for the jobs details page to be present again to avoid StaleElementReferenceException\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'mosaic-provider-jobcards')))\n",
    "\n",
    "    # Close the browser\n",
    "    \n",
    "\n",
    "# Call the function to scrape job details from Indeed\n",
    "scrape_indeed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def scrape_indeed():\n",
    "    # Initialize WebDriver\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "    # Open Indeed\n",
    "    driver.get('https://www.indeed.com/')\n",
    "\n",
    "    # Use WebDriverWait to wait for the search bar to be visible\n",
    "    search_bar = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '//*[@id=\"text-input-what\"]'))\n",
    "    )\n",
    "\n",
    "    # Input the search query\n",
    "    search_bar.send_keys('AI/ML Engineer')\n",
    "    search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Extract job information\n",
    "    jobs_details = driver.find_element(By.ID, 'jobsearch-JapanPage')\n",
    "    job_cards = driver.find_elements(By.CLASS_NAME, 'css-5lfssm eu4oa1w0')\n",
    "\n",
    "    for i in range(min(5, len(job_cards))):  # Ensure we don't go beyond the number of available job cards\n",
    "        # Find the job cards again to avoid StaleElementReferenceException\n",
    "        jobs_details = driver.find_element(By.ID, 'jobsearch-JapanPage')\n",
    "        job_cards = driver.find_elements(By.CLASS_NAME, 'css-5lfssm eu4oa1w0')\n",
    "\n",
    "        # Click on the current job card\n",
    "        current_job_card = job_cards[i]\n",
    "        current_job_card.click()\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            job_details = driver.find_element(By.ID, 'jobsearch-ViewjobPaneWrapper')\n",
    "\n",
    "            job_title = job_details.find_element(By.XPATH, '/html/body/main/div/div[1]/div/div[5]/div[2]/div/div/div/div/div[1]/div/div[1]/div[1]/h2')\n",
    "            company_name = job_details.find_element(By.XPATH, '/html/body/main/div/div[1]/div/div[5]/div[2]/div/div/div/div/div[1]/div/div[1]/div[2]/div/div/div/div[1]/div/span')\n",
    "            job_location = job_details.find_element(By.XPATH, '//*[@id=\"jobsearch-ViewjobPaneWrapper\"]/div/div/div/div[1]/div/div[1]/div[2]/div/div/div/div[2]')\n",
    "\n",
    "            print(f\"\\nJob details:\")\n",
    "            print(f\"Company Name: {company_name.text}\")\n",
    "            print(f\"Location: {job_location.text}\")\n",
    "            print(f\"Job Title: {job_title.text}\")\n",
    "\n",
    "        except:\n",
    "            print(\"Exception while extracting job details\")\n",
    "\n",
    "        # Go back to the previous page\n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "        # Wait for the jobs details page to be present again to avoid StaleElementReferenceException\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'mosaic-provider-jobcards')))\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "# Call the function to scrape job details from Indeed\n",
    "scrape_indeed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16272d0d",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Develop a basic movie recommendation system that scrapes data from the IMDb website. The program will retrieve information from the Most Popular Movies page on IMDb. The data to be scraped is\n",
    "\n",
    "1) Movie Titles <br>\n",
    "2) Runtime <br>\n",
    "3) Rating <br>\n",
    "4) Age Restriction <br>\n",
    "5) Genre <br>\n",
    "6) Writer(s) <br>\n",
    "7) Director(s) <br>\n",
    "8) Fun Movie Trivia <br> \n",
    "\n",
    "The data will be stored in a Pandas dataframe.\n",
    "\n",
    "Subsequently, the program will prompt the user to specify their preferences for:\n",
    "\n",
    "1) Genre <br>\n",
    "2) Minimum Rating<br>\n",
    "3) Maximum Runtime<br>\n",
    "4) Age Restriction<br>\n",
    "\n",
    "It will then filter the dataframe accordingly and select a movie for recommendation. The recommendation will display the movie title, writer, director, and trivia. If there are no movies that match the user's preferences, the program will recommend any movie from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Director</th>\n",
       "      <th>Year</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Age Restriction</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Napoleon</td>\n",
       "      <td>An epic that details the checkered rise and fa...</td>\n",
       "      <td>Ridley Scott</td>\n",
       "      <td>2023</td>\n",
       "      <td>2h 38m</td>\n",
       "      <td>R</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Hunger Games: The Ballad of Songbirds &amp; Sn...</td>\n",
       "      <td>Coriolanus Snow mentors and develops feelings ...</td>\n",
       "      <td>Francis Lawrence</td>\n",
       "      <td>2023</td>\n",
       "      <td>2h 37m</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Furiosa: A Mad Max Saga</td>\n",
       "      <td>The origin story of renegade warrior Furiosa b...</td>\n",
       "      <td>George Miller</td>\n",
       "      <td>None</td>\n",
       "      <td>0h 0m</td>\n",
       "      <td>2024</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saltburn</td>\n",
       "      <td>A student at Oxford University finds himself d...</td>\n",
       "      <td>Emerald Fennell</td>\n",
       "      <td>2023</td>\n",
       "      <td>2h 11m</td>\n",
       "      <td>R</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leo</td>\n",
       "      <td>A 74-year-old lizard named Leo and his turtle ...</td>\n",
       "      <td>Robert Marianetti</td>\n",
       "      <td>2023</td>\n",
       "      <td>1h 42m</td>\n",
       "      <td>PG</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rebel Moon: Part One - A Child of Fire</td>\n",
       "      <td>When a peaceful settlement on the edge of a di...</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>2023</td>\n",
       "      <td>2h 13m</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Memory</td>\n",
       "      <td>Sylvia is a social worker who leads a simple a...</td>\n",
       "      <td>Michel Franco</td>\n",
       "      <td>2023</td>\n",
       "      <td>1h 40m</td>\n",
       "      <td>R</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Dune</td>\n",
       "      <td>A noble family becomes embroiled in a war for ...</td>\n",
       "      <td>Denis Villeneuve</td>\n",
       "      <td>2021</td>\n",
       "      <td>2h 35m</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Argylle</td>\n",
       "      <td>An introverted spy novelist is drawn into the ...</td>\n",
       "      <td>Matthew Vaughn</td>\n",
       "      <td>2024</td>\n",
       "      <td>0h 0m</td>\n",
       "      <td>2024\\n2h 15m</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A Christmas Story</td>\n",
       "      <td>In the 1940s, a young boy named Ralphie Parker...</td>\n",
       "      <td>Bob Clark</td>\n",
       "      <td>1983</td>\n",
       "      <td>1h 33m</td>\n",
       "      <td>PG</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0                                            Napoleon   \n",
       "1   The Hunger Games: The Ballad of Songbirds & Sn...   \n",
       "2                             Furiosa: A Mad Max Saga   \n",
       "3                                            Saltburn   \n",
       "4                                                 Leo   \n",
       "..                                                ...   \n",
       "95             Rebel Moon: Part One - A Child of Fire   \n",
       "96                                             Memory   \n",
       "97                                               Dune   \n",
       "98                                            Argylle   \n",
       "99                                  A Christmas Story   \n",
       "\n",
       "                                          Description           Director  \\\n",
       "0   An epic that details the checkered rise and fa...       Ridley Scott   \n",
       "1   Coriolanus Snow mentors and develops feelings ...   Francis Lawrence   \n",
       "2   The origin story of renegade warrior Furiosa b...      George Miller   \n",
       "3   A student at Oxford University finds himself d...    Emerald Fennell   \n",
       "4   A 74-year-old lizard named Leo and his turtle ...  Robert Marianetti   \n",
       "..                                                ...                ...   \n",
       "95  When a peaceful settlement on the edge of a di...        Zack Snyder   \n",
       "96  Sylvia is a social worker who leads a simple a...      Michel Franco   \n",
       "97  A noble family becomes embroiled in a war for ...   Denis Villeneuve   \n",
       "98  An introverted spy novelist is drawn into the ...     Matthew Vaughn   \n",
       "99  In the 1940s, a young boy named Ralphie Parker...          Bob Clark   \n",
       "\n",
       "    Year Runtime Age Restriction Ratings  \n",
       "0   2023  2h 38m               R     6.6  \n",
       "1   2023  2h 37m           PG-13     7.2  \n",
       "2   None   0h 0m            2024    None  \n",
       "3   2023  2h 11m               R     7.5  \n",
       "4   2023  1h 42m              PG     7.0  \n",
       "..   ...     ...             ...     ...  \n",
       "95  2023  2h 13m           PG-13    None  \n",
       "96  2023  1h 40m               R     7.0  \n",
       "97  2021  2h 35m           PG-13     8.0  \n",
       "98  2024   0h 0m    2024\\n2h 15m    None  \n",
       "99  1983  1h 33m              PG     7.9  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already initialized the driver\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
    "driver.get(url)\n",
    "button = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/div[3]/section/div/div[2]/div/div[1]/div/div/button[1]')\n",
    "button.click()\n",
    "\n",
    "movies_data = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/div[3]/section/div/div[2]/div/ul')\n",
    "movies_info = movies_data.find_elements(By.CLASS_NAME, 'ipc-metadata-list-summary-item')\n",
    "\n",
    "movies_description = []\n",
    "movies_name = []\n",
    "movies_watch_time = []\n",
    "counter = 1\n",
    "directors = []\n",
    "ratings = []\n",
    "\n",
    "for i in movies_info:\n",
    "    descrption = i.find_element(By.CLASS_NAME, 'ipc-html-content-inner-div')\n",
    "    name = i.find_element(By.CLASS_NAME, 'ipc-title__text')\n",
    "    length = i.find_element(By.XPATH, f'//*[@id=\"__next\"]/main/div/div[3]/section/div/div[2]/div/ul/li[{counter}]/div[1]/div/div/div[1]/div[2]/div[3]')\n",
    "    director = i.find_element(By.XPATH, f'/html/body/div[2]/main/div/div[3]/section/div/div[2]/div/ul/li[{counter}]/div[1]/div/div/div[2]/span[2]')\n",
    "\n",
    "    try:    \n",
    "        rating_raw = i.find_element(By.XPATH, f'/html/body/div[2]/main/div/div[3]/section/div/div[2]/div/ul/li[{counter}]/div[1]/div/div/div[1]/div[2]/span/div/span').text\n",
    "        # Extract only the first character (digit) from the rating\n",
    "        rating = rating_raw[0:3] if rating_raw else None\n",
    "    except NoSuchElementException:\n",
    "        rating = None\n",
    "\n",
    "    movies_description.append(descrption.text)\n",
    "    movies_name.append(name.text)\n",
    "    movies_watch_time.append(length.text)\n",
    "    directors.append(director.text)\n",
    "    ratings.append(rating)\n",
    "    counter += 1\n",
    "\n",
    "years = []\n",
    "runtimes = []\n",
    "age_restrictions = []\n",
    "\n",
    "for data in movies_watch_time:\n",
    "    # Extract year\n",
    "    year_start = 0\n",
    "    year_end = data.find('\\n')\n",
    "    year = data[year_start:year_end] if year_end != -1 else None\n",
    "    years.append(year)\n",
    "\n",
    "    # Extract runtime\n",
    "    runtime_start = year_end + 1\n",
    "    runtime_end = data.find('\\n', runtime_start)\n",
    "    runtime_data = data[runtime_start:runtime_end] if runtime_end != -1 else '0h 0m'\n",
    "    runtime_parts = runtime_data.split()\n",
    "    hours = runtime_parts[0] if runtime_parts else '0h'\n",
    "    minutes = runtime_parts[1] if len(runtime_parts) > 1 else '0m'\n",
    "    runtime = f'{hours} {minutes}'\n",
    "    runtimes.append(runtime)\n",
    "\n",
    "    # Extract age restriction\n",
    "    age_start = runtime_end + 1\n",
    "    age_end = None if age_start >= len(data) else len(data)\n",
    "    age = data[age_start:age_end] if age_end is not None and age_end > age_start else None\n",
    "    age_restrictions.append(age)\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'Name': movies_name,\n",
    "    'Description': movies_description,\n",
    "    'Director': directors,\n",
    "    'Year': years,\n",
    "    'Runtime': runtimes,\n",
    "    'Age Restriction': age_restrictions,\n",
    "    'Ratings': ratings\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8efa62e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "                                         Movie Names Ratings Release years  \\\n",
      "0                                           Napoleon     6.6          2023   \n",
      "1  The Hunger Games: The Ballad of Songbirds & Sn...     7.2          2023   \n",
      "2                                            Furiosa     7.5          2024   \n",
      "3                                           Saltburn     7.0          2023   \n",
      "4                                                Leo     8.4          2023   \n",
      "\n",
      "  Durations Age Restricition  \n",
      "0    2h 38m                R  \n",
      "1    2h 37m            PG-13  \n",
      "2      None             None  \n",
      "3    2h 11m                R  \n",
      "4    1h 42m               PG  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "data = pd.read_csv('IMDB_TOP_MOVIES.csv')\n",
    "\n",
    "# Prompt the user for preferences\n",
    "genre = input(\"Enter your preferred Genre: \")\n",
    "min_rating = float(input(\"Enter the minimum rating you prefer: \"))\n",
    "max_runtime = int(input(\"Enter the maximum runtime you prefer (in minutes): \"))\n",
    "age_restriction = input(\"Enter your preferred Age Restriction (e.g., 'R', 'PG', 'TV-MA', 'Not Rated'): \")\n",
    "\n",
    "# Filter the DataFrame based on user preferences\n",
    "filtered_data = data[\n",
    "    (data['Ratings'].apply(lambda x: float(x) if x != 'NA' else None) >= min_rating) &\n",
    "    (data['Durations'].apply(lambda x: int(x.split('h')[0]) if pd.notnull(x) else None) <= max_runtime) &\n",
    "    ((data['Age Restricition'] == age_restriction) | (pd.isnull(data['Age Restricition'])))\n",
    "]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"\\nFiltered Movies:\")\n",
    "filtered_data\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_data.to_csv('Filtered_IMDB_MOVIES.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movie_data_file_.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b981671",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "In Question 3, your objective is to find the best available product on Daraz, specifically the Redmi Note 12 smartphone. You will scrape important information from the products listed on the first five pages, which includes the Product Title, Rating, Free Shipping Status, Daraz Mall status, Seller Rating and the Ship on Time score.\n",
    "\n",
    "To find the best available product, apply the following scoring criteria to each product:\n",
    "\n",
    "<b>1) </b> The price will be the base score.<br>\n",
    "<b>2) </b> Award an additional 5,000 points to products with the \"Daraz Mall\" status.<br>\n",
    "<b>3) </b> Grant an extra 1,000 points to products with free shipping.<br>\n",
    "<b>4) </b> Add 10000*((0.4 * (Product Rating / 5)) + (0.4 * (Seller Rating / 100)) + (0.2 * (Shipping Performance / 100)) to the score <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.daraz.pk/'\n",
    "driver.get(url)\n",
    "search_bar = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div/div[2]/div/div[2]/form/div/div[1]/input[1]')\n",
    "search_bar.send_keys('Redmi Note 12' + Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b963cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Best Product Details:\n",
      "Name: Xiaomi Redmi Note 12 || 8GB Ram 128GB Rom || 5000mAh Battery 33W Fast Charger\n",
      "Price: Rs. 51,499\n",
      "Daraz Mall Status: No\n",
      "Free Shipping: Yes\n",
      "Product Rating: 4.7\n",
      "Seller Rating: 90%\n",
      "Shipping Performance: 81%\n",
      "Total Score: 61479.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ad_grid = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[3]/div/div/div[1]/div[2]')\n",
    "ad_cards = ad_grid.find_elements(By.CLASS_NAME, 'gridItem--Yd0sa')\n",
    "# Loop through each ad card, click on it, and then return to the previous page\n",
    "price_mobile = []\n",
    "dilivery_status = []\n",
    "ratings_list = []\n",
    "seller_ratings_list = []\n",
    "Shipping_performance = []\n",
    "flagship_mall = []\n",
    "scores = []\n",
    "product_name = []\n",
    "\n",
    "for index in range(0,5):\n",
    "    # Find the ad cards again to avoid StaleElementReferenceException\n",
    "    ad_grid = driver.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[3]/div/div/div[1]/div[2]')\n",
    "    ad_cards = ad_grid.find_elements(By.CLASS_NAME, 'gridItem--Yd0sa')\n",
    "    \n",
    "    # Click on the current ad card\n",
    "    current_card = ad_cards[index]\n",
    "    current_card.click()\n",
    "    Information_grid = driver.find_element(By.XPATH, '/html/body/div[4]/div/div[3]')\n",
    "    prices = Information_grid.find_elements(By.CLASS_NAME, 'pdp-product-price')\n",
    "    price_ = Information_grid.find_element(By.XPATH, '//*[@id=\"module_product_price_1\"]/div/div/span')\n",
    "    price_mobile.append(price_.text)\n",
    "    \n",
    "\n",
    "    dilivery_bar = driver.find_element(By.XPATH, '/html/body/div[4]/div/div[3]/div[2]/div/div[2]')\n",
    "    dilivery_opt = driver.find_elements(By.CLASS_NAME, 'delivery-option-item__title')\n",
    "    Seller_rating = dilivery_bar.find_element(By.XPATH, '/html/body/div[4]/div/div[3]/div[2]/div/div[2]/div[5]/div/div[2]/div[1]/div[2]')\n",
    "    Shipping_perf = dilivery_bar.find_element(By.XPATH, '//*[@id=\"module_seller_info\"]/div/div[2]/div[2]/div[2]')\n",
    "    flagship_mall_xpath = '//*[@id=\"module_seller_info\"]/div/div[1]/div[1]/div[2]/a[2]/img'\n",
    "    name_of_product = Information_grid.find_element(By.XPATH, '//*[@id=\"module_product_title_1\"]/div/div')\n",
    "    product_name.append(name_of_product.text)\n",
    "    flagship_mall_element = dilivery_bar.find_elements(By.XPATH, flagship_mall_xpath)\n",
    "    if flagship_mall_element:\n",
    "        flagship_mall.append(1)\n",
    "    else:\n",
    "        flagship_mall.append(0)\n",
    "    seller_ratings_list.append(Seller_rating.text)\n",
    "    Shipping_performance.append(Shipping_perf.text)\n",
    "    driver.execute_script(\"window.scrollTo(0, 500);\")\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"window.scrollTo(500, 800);\")\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"window.scrollTo(800, 1000);\")\n",
    "    time.sleep(2)\n",
    "    rating_bar = driver.find_element(By.XPATH, '//*[@id=\"module_product_review\"]')\n",
    "    rating = rating_bar.find_element(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[1]/div[2]/div/div/div[1]/div[1]/span[1]')\n",
    "    ratings_list.append(rating.text)\n",
    "    counter = 0\n",
    "    for i in dilivery_opt:\n",
    "        if 'Free Delivery' in (i.text):\n",
    "            counter+=1\n",
    "            dilivery_status.append(1)\n",
    "    if(counter==0):\n",
    "        dilivery_status.append(0)\n",
    "    \n",
    "    # Calculate the base score (price)\n",
    "    base_score = int(price_mobile[index].replace('Rs. ', '').replace(',', ''))\n",
    "\n",
    "    # Check if the product has \"Daraz Mall\" status\n",
    "    daraz_mall_score = 5000 if flagship_mall[index] == 1 else 0\n",
    "\n",
    "    # Check if the product has free shipping\n",
    "    free_shipping_score = 1000 if dilivery_status[index] == 1 else 0\n",
    "    product_rating = float(ratings_list[index])\n",
    "    seller_rating = float(seller_ratings_list[index].replace('%', ''))\n",
    "    shipping_performance = float(Shipping_performance[index].replace('%', ''))\n",
    "    score = base_score + daraz_mall_score + free_shipping_score + 10000 * (\n",
    "        (0.4 * (product_rating / 5)) + (0.4 * (seller_rating / 100)) + (0.2 * (shipping_performance / 100))\n",
    "    )\n",
    "    \n",
    "    scores.append(score)\n",
    "\n",
    "    time.sleep(2)  # Add a short delay to allow the page to load\n",
    "\n",
    "\n",
    "    # Go back to the previous page\n",
    "    driver.back()\n",
    "    # Wait for the ad grid to be present again to avoid StaleElementReferenceException\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div/div[3]/div/div/div[1]/div[2]')))\n",
    "best_product_index = scores.index(max(scores))\n",
    "\n",
    "# Print the details of the best product\n",
    "print(f\"Best Product Details:\")\n",
    "print(f\"Name: {product_name[best_product_index]}\")\n",
    "print(f\"Price: {price_mobile[best_product_index]}\")\n",
    "print(f\"Daraz Mall Status: {'Yes' if flagship_mall[best_product_index] == 1 else 'No'}\")\n",
    "print(f\"Free Shipping: {'Yes' if dilivery_status[best_product_index] == 1 else 'No'}\")\n",
    "print(f\"Product Rating: {ratings_list[best_product_index]}\")\n",
    "print(f\"Seller Rating: {seller_ratings_list[best_product_index]}\")\n",
    "print(f\"Shipping Performance: {Shipping_performance[best_product_index]}\")\n",
    "print(f\"Total Score: {scores[best_product_index]}\")\n",
    "ad_cards[best_product_index].click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51adc467",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Having successfully identified the best product, proceed to its product page on Daraz. Your task is to scrape the product's reviews and perform sentiment analysis on these reviews. To conduct sentiment analysis, you can utilize the NLTK (Natural Language Toolkit) library, which will help you determine the sentiment expressed in the text of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Shahz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_cards[best_product_index].click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Review text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdul G.</td>\n",
       "      <td>Assalam u Alaikum\\nReceived before due date or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S***n</td>\n",
       "      <td>The seller was very cooperative and delivered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*******686</td>\n",
       "      <td>Same as described.. Amazing Packing and receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sadaqat A.</td>\n",
       "      <td>The product was the same as mentioned in the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M***.</td>\n",
       "      <td>Ordered on Friday Afternoon and received on Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M***.</td>\n",
       "      <td>Ordered on Friday Afternoon and received on Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zain A.</td>\n",
       "      <td>Original phone, everything was OK, delivered o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qasim I.</td>\n",
       "      <td>original  product and timely response and deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3***9</td>\n",
       "      <td>Masha Allah Jo select kia tha wohi same receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arslan Z.</td>\n",
       "      <td>#ReviewWorldCup\\n#RWC\\nOther than camera, its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M***.</td>\n",
       "      <td>Ordered on Friday Afternoon and received on Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zain A.</td>\n",
       "      <td>Original phone, everything was OK, delivered o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qasim I.</td>\n",
       "      <td>original  product and timely response and deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3***9</td>\n",
       "      <td>Masha Allah Jo select kia tha wohi same receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Arslan Z.</td>\n",
       "      <td>#ReviewWorldCup\\n#RWC\\nOther than camera, its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M***.</td>\n",
       "      <td>Ordered on Friday Afternoon and received on Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zain A.</td>\n",
       "      <td>Original phone, everything was OK, delivered o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qasim I.</td>\n",
       "      <td>original  product and timely response and deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3***9</td>\n",
       "      <td>Masha Allah Jo select kia tha wohi same receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Arslan Z.</td>\n",
       "      <td>#ReviewWorldCup\\n#RWC\\nOther than camera, its ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name                                        Review text\n",
       "0     Abdul G.  Assalam u Alaikum\\nReceived before due date or...\n",
       "1        S***n  The seller was very cooperative and delivered ...\n",
       "2   *******686  Same as described.. Amazing Packing and receiv...\n",
       "3   Sadaqat A.  The product was the same as mentioned in the o...\n",
       "4        M***.  Ordered on Friday Afternoon and received on Mo...\n",
       "5        M***.  Ordered on Friday Afternoon and received on Mo...\n",
       "6      Zain A.  Original phone, everything was OK, delivered o...\n",
       "7     Qasim I.  original  product and timely response and deli...\n",
       "8        3***9  Masha Allah Jo select kia tha wohi same receiv...\n",
       "9    Arslan Z.  #ReviewWorldCup\\n#RWC\\nOther than camera, its ...\n",
       "10       M***.  Ordered on Friday Afternoon and received on Mo...\n",
       "11     Zain A.  Original phone, everything was OK, delivered o...\n",
       "12    Qasim I.  original  product and timely response and deli...\n",
       "13       3***9  Masha Allah Jo select kia tha wohi same receiv...\n",
       "14   Arslan Z.  #ReviewWorldCup\\n#RWC\\nOther than camera, its ...\n",
       "15       M***.  Ordered on Friday Afternoon and received on Mo...\n",
       "16     Zain A.  Original phone, everything was OK, delivered o...\n",
       "17    Qasim I.  original  product and timely response and deli...\n",
       "18       3***9  Masha Allah Jo select kia tha wohi same receiv...\n",
       "19   Arslan Z.  #ReviewWorldCup\\n#RWC\\nOther than camera, its ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "temp = {'Name': [], 'Review text': []}\n",
    "\n",
    "def scroll_to(driver, y_position):\n",
    "    driver.execute_script(f\"window.scrollTo(0, {y_position});\")\n",
    "\n",
    "def get_reviews(driver, temp):\n",
    "    try:\n",
    "        reviews_container = driver.find_element(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[3]/div[1]')\n",
    "    except NoSuchElementException:\n",
    "        print('No Reviews')\n",
    "        return\n",
    "\n",
    "    reviews = reviews_container.find_elements(By.CLASS_NAME, 'item')\n",
    "\n",
    "    for i, review in enumerate(reviews):\n",
    "        content = review.find_element(By.CLASS_NAME, 'content').text\n",
    "        if content:\n",
    "            name = review.find_element(By.CLASS_NAME, 'middle').find_element(By.TAG_NAME, 'span').text[3:]\n",
    "            temp['Name'].append(name)\n",
    "            temp['Review text'].append(content)\n",
    "\n",
    "def click_next_button(driver):\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"module_product_review\"]/div/div/div[3]/div[2]/div/div/button[2]')\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        time.sleep(5)\n",
    "    except NoSuchElementException:\n",
    "        print('No More Pages')\n",
    "\n",
    "# Initial scroll\n",
    "scroll_to(driver, 1600)\n",
    "time.sleep(2)\n",
    "\n",
    "# Loop through pages\n",
    "for page in range(4):\n",
    "    get_reviews(driver, temp)\n",
    "    click_next_button(driver)\n",
    "\n",
    "# Create DataFrame\n",
    "reviews = pd.DataFrame(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name                                        Review text Sentiment\n",
      "0     Abdul G.  Assalam u Alaikum\\nReceived before due date or...   Nuetral\n",
      "1        S***n  The seller was very cooperative and delivered ...   Nuetral\n",
      "2   *******686  Same as described.. Amazing Packing and receiv...   Nuetral\n",
      "3   Sadaqat A.  The product was the same as mentioned in the o...  Positive\n",
      "4        M***.  Ordered on Friday Afternoon and received on Mo...   Nuetral\n",
      "5        M***.  Ordered on Friday Afternoon and received on Mo...   Nuetral\n",
      "6      Zain A.  Original phone, everything was OK, delivered o...  Positive\n",
      "7     Qasim I.  original  product and timely response and deli...  Positive\n",
      "8        3***9  Masha Allah Jo select kia tha wohi same receiv...  Positive\n",
      "9    Arslan Z.  #ReviewWorldCup\\n#RWC\\nOther than camera, its ...  Positive\n",
      "10       M***.  Ordered on Friday Afternoon and received on Mo...   Nuetral\n",
      "11     Zain A.  Original phone, everything was OK, delivered o...  Positive\n",
      "12    Qasim I.  original  product and timely response and deli...  Positive\n",
      "13       3***9  Masha Allah Jo select kia tha wohi same receiv...  Positive\n",
      "14   Arslan Z.  #ReviewWorldCup\\n#RWC\\nOther than camera, its ...  Positive\n",
      "15       M***.  Ordered on Friday Afternoon and received on Mo...   Nuetral\n",
      "16     Zain A.  Original phone, everything was OK, delivered o...  Positive\n",
      "17    Qasim I.  original  product and timely response and deli...  Positive\n",
      "18       3***9  Masha Allah Jo select kia tha wohi same receiv...  Positive\n",
      "19   Arslan Z.  #ReviewWorldCup\\n#RWC\\nOther than camera, its ...  Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "\n",
    "# Assuming you have a DataFrame called 'reviews' with 'Name' and 'Review text' columns\n",
    "\n",
    "# Define a dictionary of positive words and emojis\n",
    "positive_words = ['good', 'kind', 'positive', 'fast', 'excellent', 'amazing', 'awesome', 'fantastic', 'genuine', 'on time', 'original', 'zabrdast', 'geniun', 'well', 'Thank you', 'Thanks', 'satisfying', 'pleasing', 'superb', 'outstanding', 'impressive', 'stellar', 'remarkable', 'awesome', 'amazing']\n",
    "negative_words = ['bad', 'poor', 'negative', 'slow', 'disappointing', 'horrible', 'awful', 'terrible', 'fake', 'not genuine', 'late', 'worst', 'unpleasant', 'problematic', 'displeased', 'regret']\n",
    "positive_emojis = ['😊', '👍', '🌟', '😄', '🎉']\n",
    "negative_emojis = ['😞', '👎', '💔', '😢', '😔', '😡', '🤬', '😤', '😠']\n",
    "\n",
    "# Combine positive words and emojis into a single list\n",
    "positive_lexicon = positive_words + positive_emojis\n",
    "negative_lexicon = negative_words + negative_emojis\n",
    "# Define a function to get sentiment using the custom positive lexicon\n",
    "\n",
    "def get_sentiment_with_lexicon(text):\n",
    "    # Check if any positive word or emoji is present in the text\n",
    "    counter_positive_words = 0\n",
    "    counter_negative_words = 0\n",
    "    if any(word in text for word in positive_lexicon):\n",
    "        counter_positive_words += 1\n",
    "        \n",
    "    if any(word in text for word in negative_words):  # Fixed the typo here\n",
    "        counter_negative_words += 1\n",
    "        \n",
    "    if counter_negative_words < counter_positive_words:\n",
    "        return 'Positive'\n",
    "    elif counter_negative_words > counter_positive_words:\n",
    "        return 'Negative'\n",
    "    if(counter_positive_words==counter_negative_words):\n",
    "        return 'Nuetral'\n",
    "    else:\n",
    "        return 'Neutral'  # Assume neutral if no positive word or emoji is found\n",
    "# Add a new 'Sentiment' column to the DataFrame using the custom lexicon\n",
    "reviews['Sentiment'] = reviews['Review text'].apply(get_sentiment_with_lexicon)\n",
    "\n",
    "# Display the DataFrame with sentiments\n",
    "print(reviews)\n",
    "\n",
    "# Save the DataFrame with sentiments to a CSV file\n",
    "reviews.to_csv('Reviews_with_Sentiments.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
