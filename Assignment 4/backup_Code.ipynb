{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نہ پُوچھ شگفتگی ہے اتراتا وگرنہ میں\n",
      "ھے کس سے آپ ہی سے ھیں\n",
      "کئے ہوئے ہیں گرفتارِ وفا، زنداں میں\n",
      "گرم طواف اولیٰ بہت ستمگر کو پردے میں\n",
      "\n",
      "کے اپنی کیا ہے جس کو دعائیں\n",
      "تو دیتا ہے بجلی سے ملتیں جب سر پر پڑیں\n",
      "تیرے آئے ہیں فاش رموز قلندری میری چینِ جبیں\n",
      "نہ دوں غالب اس کی پرواز میں\n",
      "\n",
      "خودی کی موت وہ نہیں کرتے ہیں\n",
      "کی یا رب خداوندان مکتب کی جزا کہیں\n",
      "ہوگا تمہاری تہذیب اپنے کو‘ کبھی تو غربت میں\n",
      "دی پرہیز بچھائی ہے وہی اول دیتے ہیں\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk import ngrams\n",
    "\n",
    "# Load the Poetry list from iqbal.txt and ghalib.txt\n",
    "poetry_list = []\n",
    "\n",
    "with open('iqbal.txt', 'r', encoding='utf-8') as file:\n",
    "    poetry_list += file.read().splitlines()\n",
    "\n",
    "with open('ghalib.txt', 'r', encoding='utf-8') as file:\n",
    "    poetry_list += file.read().splitlines()\n",
    "\n",
    "# Tokenize the poetry_list into words\n",
    "\n",
    "words = []\n",
    "for line in poetry_list:\n",
    "    word_list = line.split()\n",
    "    for word in word_list:\n",
    "        words.append(word)\n",
    "\n",
    "# Generate Bigram words\n",
    "bigram_words = {}\n",
    "\n",
    "for word1, word2 in ngrams(words, 2):\n",
    "    if word1 not in bigram_words:\n",
    "        bigram_words[word1] = []\n",
    "    bigram_words[word1].append(word2)\n",
    "\n",
    "# Function to generate a ghazal verse using a model\n",
    "def generate_ghazal_verse(model, length_range):\n",
    "    verse = []\n",
    "    length = random.randint(length_range[0], length_range[1])\n",
    "    \n",
    "    while length > 0:\n",
    "        if not verse:\n",
    "            # Start with a random word from the poetry list\n",
    "            current_word = random.choice(words)\n",
    "        else:\n",
    "            # Choose the next word based on the bigram words\n",
    "            next_words = model.get(verse[-1], [])\n",
    "            if not next_words:\n",
    "                break\n",
    "            current_word = random.choice(next_words)\n",
    "        \n",
    "        verse.append(current_word)\n",
    "        length -= 1\n",
    "    \n",
    "    return verse\n",
    "\n",
    "# Function to check if the last word of the verses rhyme\n",
    "def last_words_rhyme(verses):\n",
    "    last_word = verses[0][-1]\n",
    "    for verse in verses[1:]:\n",
    "        if last_word[-2:] != verse[-1][-2:]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Generating full ghazal with rhyming stanza \n",
    "def generate_complete_ghazal(stanza_count, verses_per_stanza):\n",
    "    for _ in range(stanza_count):\n",
    "        while True:\n",
    "            \n",
    "            rhyming_verses = []\n",
    "            for _ in range(verses_per_stanza):\n",
    "                verse = generate_ghazal_verse(bigram_words, (7, 10))\n",
    "                rhyming_verses.append(verse)\n",
    "            \n",
    "            if last_words_rhyme(rhyming_verses):\n",
    "                break\n",
    "        \n",
    "        for verse in rhyming_verses:\n",
    "            print(\" \".join(verse))\n",
    "        \n",
    "        print()  \n",
    "\n",
    "generate_complete_ghazal(3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arabic': 0, 'azerbaijani': 3, 'basque': 0, 'bengali': 0, 'catalan': 3, 'chinese': 0, 'danish': 0, 'dutch': 5, 'english': 9, 'finnish': 0, 'french': 1, 'german': 1, 'greek': 0, 'hebrew': 0, 'hinglish': 12, 'hungarian': 1, 'indonesian': 1, 'italian': 2, 'kazakh': 0, 'nepali': 0, 'norwegian': 0, 'portuguese': 1, 'romanian': 1, 'russian': 0, 'slovene': 0, 'spanish': 1, 'swedish': 0, 'tajik': 0, 'turkish': 0}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define a dictionary to store the counts of stopwords for each language\n",
    "def classify_language(text):\n",
    "    language_counts = {\n",
    "        'arabic': 0,\n",
    "        'azerbaijani': 0,\n",
    "        'basque': 0,\n",
    "        'bengali': 0,\n",
    "        'catalan': 0,\n",
    "        'chinese': 0,\n",
    "        'danish': 0,\n",
    "        'dutch': 0,\n",
    "        'english': 0,\n",
    "        'finnish': 0,\n",
    "        'french': 0,\n",
    "        'german': 0,\n",
    "        'greek': 0,\n",
    "        'hebrew': 0,\n",
    "        'hinglish': 0,\n",
    "        'hungarian': 0,\n",
    "        'indonesian': 0,\n",
    "        'italian': 0,\n",
    "        'kazakh': 0,\n",
    "        'nepali': 0,\n",
    "        'norwegian': 0,\n",
    "        'portuguese': 0,\n",
    "        'romanian': 0,\n",
    "        'russian': 0,\n",
    "        'slovene': 0,\n",
    "        'spanish': 0,\n",
    "        'swedish': 0,\n",
    "        'tajik': 0,\n",
    "        'turkish': 0\n",
    "    }\n",
    "\n",
    "    # Tokenize the text and remove punctuation\n",
    "    words = nltk.wordpunct_tokenize(text.lower())\n",
    "\n",
    "    # Define stopwords for each language\n",
    "    language_stopwords = {\n",
    "        'arabic': set(stopwords.words('arabic')),\n",
    "        'azerbaijani': set(stopwords.words('azerbaijani')),\n",
    "        'basque': set(stopwords.words('basque')),\n",
    "        'bengali': set(stopwords.words('bengali')),\n",
    "        'catalan': set(stopwords.words('catalan')),\n",
    "        'chinese': set(stopwords.words('chinese')),\n",
    "        'danish': set(stopwords.words('danish')),\n",
    "        'dutch': set(stopwords.words('dutch')),\n",
    "        'english': set(stopwords.words('english')),\n",
    "        'finnish': set(stopwords.words('finnish')),\n",
    "        'french': set(stopwords.words('french')),\n",
    "        'german': set(stopwords.words('german')),\n",
    "        'greek': set(stopwords.words('greek')),\n",
    "        'hebrew': set(stopwords.words('hebrew')),\n",
    "        'hinglish': set(stopwords.words('hinglish')),\n",
    "        'hungarian': set(stopwords.words('hungarian')),\n",
    "        'indonesian': set(stopwords.words('indonesian')),\n",
    "        'italian': set(stopwords.words('italian')),\n",
    "        'kazakh': set(stopwords.words('kazakh')),\n",
    "        'nepali': set(stopwords.words('nepali')),\n",
    "        'norwegian': set(stopwords.words('norwegian')),\n",
    "        'portuguese': set(stopwords.words('portuguese')),\n",
    "        'romanian': set(stopwords.words('romanian')),\n",
    "        'russian': set(stopwords.words('russian')),\n",
    "        'slovene': set(stopwords.words('slovene')),\n",
    "        'spanish': set(stopwords.words('spanish')),\n",
    "        'swedish': set(stopwords.words('swedish')),\n",
    "        'tajik': set(stopwords.words('tajik')),\n",
    "        'turkish': set(stopwords.words('turkish'))\n",
    "    }\n",
    "\n",
    "    # Classify words by language and count stopwords for each language\n",
    "    for word in words:\n",
    "        for language, stopwords_list in language_stopwords.items():\n",
    "\n",
    "            if word in stopwords_list:\n",
    "                language_counts[language] += 1\n",
    "\n",
    "    # Return the language counts\n",
    "    return language_counts\n",
    "\n",
    "# Test text\n",
    "test = \"An article is qualunque member van un class of dedicated words naquele estão used with noun phrases per mark the identifiability of the referents of the noun phrases\"\n",
    "\n",
    "result = classify_language(test)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "گیا اب کوئی اداس بیٹھا ستم ایجاد! نہیں\n",
      "رباب میں آرایش لباسِ نظم میں تمھیں پندارِ خدائی میں\n",
      "باد ء رسوا ہوئے جاتا ہوں آتش ناک میں\n",
      "کرے ہے چراغِ محفل اٹھ گئی ہے ہاں بھلا نہیں\n",
      "\n",
      "کہ میں زہر ہلاہل کو کیا ہے\n",
      "تھا کہ ’’ جاؤں کدھر کو صوفی میں ہے\n",
      "ہے آسایشِ اربابِ غفلت میں ہیں چراغ محفل ہے\n",
      "ادراک اک لفظ کہ یک گوشہ بساط ہے\n",
      "\n",
      "کہتے ہیں ہزاروں بنوں میں لگی صدا میں\n",
      "جز مرگ کا دیکھتا ہوں میں نقشِ قدم میں ہیں\n",
      "کہو کیا غالب! کہ ملے شیخ حرم میں\n",
      "کا کیا فائدہ یاروں کو دو ملت میں\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk import ngrams\n",
    "\n",
    "# Load the Poetry list from iqbal.txt and ghalib.txt\n",
    "poetry_list = []\n",
    "\n",
    "with open('iqbal.txt', 'r', encoding='utf-8') as file:\n",
    "    poetry_list += file.read().splitlines()\n",
    "\n",
    "with open('ghalib.txt', 'r', encoding='utf-8') as file:\n",
    "    poetry_list += file.read().splitlines()\n",
    "\n",
    "# Tokenize the poetry_list into words\n",
    "\n",
    "words = []\n",
    "for line in poetry_list:\n",
    "    word_list = line.split()\n",
    "    for word in word_list:\n",
    "        words.append(word)\n",
    "\n",
    "# Generate Bigram Model\n",
    "bigram_model = {}\n",
    "\n",
    "for word1, word2 in ngrams(words, 2):\n",
    "    if word1 not in bigram_model:\n",
    "        bigram_model[word1] = []\n",
    "    bigram_model[word1].append(word2)\n",
    "\n",
    "# Function to generate a ghazal verse using a model\n",
    "def generate_ghazal_verse(model, length_range):\n",
    "    verse = []\n",
    "    length = random.randint(length_range[0], length_range[1])\n",
    "    \n",
    "    while length > 0:\n",
    "        if not verse:\n",
    "            # Start with a random word from the corpus\n",
    "            current_word = random.choice(words)\n",
    "        else:\n",
    "            # Choose the next word based on the bigram model\n",
    "            next_words = model.get(verse[-1], [])\n",
    "            if not next_words:\n",
    "                break\n",
    "            current_word = random.choice(next_words)\n",
    "        \n",
    "        verse.append(current_word)\n",
    "        length -= 1\n",
    "    \n",
    "    return verse\n",
    "\n",
    "# Function to check if the last words of the verses rhyme\n",
    "def last_words_rhyme(verses):\n",
    "    last_word = verses[0][-1]\n",
    "    for verse in verses[1:]:\n",
    "        if last_word[-2:] != verse[-1][-2:]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Generate a complete ghazal with multiple stanzas with rhyming last words\n",
    "def generate_complete_ghazal(stanza_count, verses_per_stanza):\n",
    "    for _ in range(stanza_count):\n",
    "        while True:\n",
    "            rhyming_verses = []\n",
    "            for _ in range(verses_per_stanza):\n",
    "                verse = generate_ghazal_verse(bigram_model, (7, 10))\n",
    "                rhyming_verses.append(verse)\n",
    "            \n",
    "            if last_words_rhyme(rhyming_verses):\n",
    "                break\n",
    "        \n",
    "        for verse in rhyming_verses:\n",
    "            print(\" \".join(verse))\n",
    "        \n",
    "        print()  \n",
    "\n",
    "generate_complete_ghazal(3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the Poetry list from iqbal.txt and ghalib.txt\n",
    "poetry_list = []\n",
    "\n",
    "with open('iqbal.txt', 'r', encoding='utf-8') as file:\n",
    "    poetry_list += file.read().splitlines()\n",
    "\n",
    "with open('ghalib.txt', 'r', encoding='utf-8') as file:\n",
    "    poetry_list += file.read().splitlines()\n",
    "\n",
    "# Tokenize the poetry_list into words\n",
    "\n",
    "words = []\n",
    "for line in poetry_list:\n",
    "    word_list = line.split()\n",
    "    for word in word_list:\n",
    "        words.append(word)\n",
    "\n",
    "# Generate Bigram Model\n",
    "bigram_model = defaultdict(list)\n",
    "for word1, word2 in ngrams(words, 2):\n",
    "    bigram_model[word1].append(word2)\n",
    "\n",
    "# Function to generate a ghazal verse using a model\n",
    "def generate_ghazal_verse(model, length_range):\n",
    "    verse = []\n",
    "    length = random.randint(length_range[0], length_range[1])\n",
    "    \n",
    "    while length > 0:\n",
    "        if not verse:\n",
    "            # Start with a random word from the corpus\n",
    "            current_word = random.choice(words)\n",
    "        else:\n",
    "            # Choose the next word based on the bigram model\n",
    "            current_word = random.choice(model[verse[-1]])\n",
    "        \n",
    "        verse.append(current_word)\n",
    "        length -= 1\n",
    "    \n",
    "    return verse\n",
    "\n",
    "# Function to check if the last words of the verses rhyme\n",
    "def last_words_rhyme(verses):\n",
    "    last_word = verses[0][-1]\n",
    "    for verse in verses[1:]:\n",
    "        if last_word[-2:] != verse[-1][-2:]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Generate a complete ghazal with multiple stanzas with rhyming last words\n",
    "def generate_complete_ghazal(stanza_count, verses_per_stanza):\n",
    "    for _ in range(stanza_count):\n",
    "        while True:\n",
    "            rhyming_verses = []\n",
    "            for _ in range(verses_per_stanza):\n",
    "                verse = generate_ghazal_verse(bigram_model, (7, 10))\n",
    "                rhyming_verses.append(verse)\n",
    "            \n",
    "            if last_words_rhyme(rhyming_verses):\n",
    "                break\n",
    "        \n",
    "        for verse in rhyming_verses:\n",
    "            print(\" \".join(verse))\n",
    "        \n",
    "        print()  \n",
    "\n",
    "\n",
    "generate_complete_ghazal(3, 4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
